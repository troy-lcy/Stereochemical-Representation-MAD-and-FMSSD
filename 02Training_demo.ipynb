{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will compare different ML models with MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-of-sample tasks \n",
    "test_1 = pd.read_csv('BHA_model_data/test1.csv',header=None)\n",
    "test_2 = pd.read_csv('BHA_model_data/test2.csv',header=None)\n",
    "test_3 = pd.read_csv('BHA_model_data/test3.csv',header=None)\n",
    "test_4 = pd.read_csv('BHA_model_data/test4.csv',header=None)\n",
    "\n",
    "Train_234 = pd.concat([test_2,test_3,test_4], ignore_index=False) # additive 1\n",
    "Train_134 = pd.concat([test_1,test_3,test_4], ignore_index=False)\n",
    "Train_124 = pd.concat([test_1,test_2,test_4], ignore_index=False)\n",
    "Train_123 = pd.concat([test_1,test_2,test_3], ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import utils_plot_yield as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(n_estimators=50, random_state=42)\n",
      "Done fitting models\n",
      "RandomForestRegressor(n_estimators=50, random_state=42)\n",
      "Done fitting models\n",
      "RandomForestRegressor(n_estimators=50, random_state=42)\n",
      "Done fitting models\n",
      "RandomForestRegressor(n_estimators=50, random_state=42)\n",
      "Done fitting models\n"
     ]
    }
   ],
   "source": [
    "models_need_fit = [\n",
    "        #   AdaBoostRegressor(random_state=42, n_estimators=100),  \n",
    "        #   LinearRegression(),\n",
    "        #   LinearSVR(max_iter=1000),\n",
    "        #   KNeighborsRegressor(n_neighbors=7),          \n",
    "          RandomForestRegressor(n_estimators=50,random_state=42)#,\n",
    "          #MLPRegressor(hidden_layer_sizes=(1000,500), activation='logistic', solver='sgd', max_iter=10000, random_state=42, alpha=0.0001, learning_rate_init=0.00002, batch_size = len(X_train))\n",
    "         ]\n",
    "\n",
    "r2 = []\n",
    "rmse = []\n",
    "\n",
    "Train = [Train_234, Train_134, Train_124, Train_123]\n",
    "Test = [test_1, test_2, test_3, test_4]\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    X_train = np.array(Train[i].iloc[:,0:-1])\n",
    "    y_train = np.array(Train[i].iloc[:,-1]).flatten()\n",
    "    X_test = np.array(Test[i].iloc[:,0:-1])\n",
    "    y_test = np.array(Test[i].iloc[:,-1]).flatten()\n",
    "\n",
    "    preds, r2_values, rmse_values  = utils.fit_models(X_train,\n",
    "                                                    X_test,\n",
    "                                                    y_train,\n",
    "                                                    y_test,\n",
    "                                                    models_need_fit)\n",
    "    r2.append(r2_values)\n",
    "    rmse.append(rmse_values)\n",
    "    df_r2 = pd.DataFrame(r2,columns= models_need_fit)\n",
    "    df_rmse = pd.DataFrame(rmse,columns=models_need_fit)\n",
    "df = pd.concat([df_r2,df_rmse], axis=1, names=['R2','RMSE'])\n",
    "df.to_csv('additive_randomforest.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(n_estimators=100, random_state=42)\n",
      "LinearRegression()\n",
      "LinearSVR()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(n_neighbors=7)\n",
      "RandomForestRegressor(random_state=42)\n",
      "Done fitting models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.5175457405708022,\n",
       "  -4.8144051438519637e+24,\n",
       "  -30.90692901705766,\n",
       "  0.5831791351790255,\n",
       "  0.5227962518819942],\n",
       " [18.37089634789537,\n",
       "  58032808865906.98,\n",
       "  149.39799786543387,\n",
       "  17.075640366789838,\n",
       "  18.27065837988394])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train = [Train_234, Train_134, Train_124, Train_123]\n",
    "Test = [test_1, test_2, test_3, test_4]\n",
    "\n",
    "\n",
    "X_train = np.array(Train[3].iloc[:,0:-1])\n",
    "y_train = np.array(Train[3].iloc[:,-1]).flatten()\n",
    "X_test = np.array(Test[3].iloc[:,0:-1])\n",
    "y_test = np.array(Test[3].iloc[:,-1]).flatten()\n",
    "\n",
    "preds, r2_values, rmse_values  = utils.fit_models(X_train,\n",
    "                                                X_test,\n",
    "                                                y_train,\n",
    "                                                y_test,\n",
    "                                                models_need_fit)\n",
    "r2_values, rmse_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7838008460417127\n",
      "12.687032572793361\n",
      "0.7522100489828267\n",
      "13.485462574189343\n",
      "0.6797841893904342\n",
      "15.909563845852539\n",
      "0.5415519348419822\n",
      "17.908010748914645\n"
     ]
    }
   ],
   "source": [
    "Train = [Train_234, Train_134, Train_124, Train_123]\n",
    "Test = [test_1, test_2, test_3, test_4]\n",
    "\n",
    "r2 = []\n",
    "rmse = []\n",
    "\n",
    "reg = xgb.XGBRegressor(\n",
    "        tree_method=\"hist\",\n",
    "        n_estimators=128,\n",
    "        n_jobs=16,\n",
    "        max_depth=8,\n",
    "        multi_strategy='one_output_per_tree',\n",
    "        subsample=0.6,\n",
    "    )\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    X_train = np.array(Train[i].iloc[:,0:-1])\n",
    "    y_train = np.array(Train[i].iloc[:,-1]).flatten()\n",
    "    X_test = np.array(Test[i].iloc[:,0:-1])\n",
    "    y_test = np.array(Test[i].iloc[:,-1]).flatten()\n",
    "\n",
    "    reg.fit(X_train,y_train)\n",
    "    preds = reg.predict(X_test)\n",
    "    r_squared = r2_score(y_test, preds)\n",
    "    rmse = mean_squared_error(y_test, preds) ** 0.5\n",
    "     \n",
    "    print(r_squared)\n",
    "    print(rmse)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unimol_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
